{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a17e50c-500e-4589-bd1e-ff9f51e97185",
   "metadata": {},
   "source": [
    "# Large Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101f5317-5eb7-4b5d-ab2c-dfe5b08bc646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrp;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The code is designed to ensure that line breaks and spaces within the code cells are properly preserved when displayed in the notebook\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "    <style>\n",
    "    pre{\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "    </style>\n",
    "    '''))\n",
    "\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190d9936-2c90-4763-9ce9-c27fd6e2b7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrp;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in the computer\n",
    "\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d146b264-6e22-4c0f-92d8-cf49396dc7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrp;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/aravindv/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aravindv/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652e5b2-5d7d-4e95-a43f-f686eeedf4e4",
   "metadata": {},
   "source": [
    "#### Get the base template from \n",
    "https://huggingface.co/docs/transformers/main/en/model_doc/flan-t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec41d9e-756a-4072-a278-b8cb33dfe876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrp;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer : \n",
      " ['Artificial intelligence is the ability to understand and understand the world.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "inputs = tokenizer(\"Explain Artificial Intelligence:\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print('Answer : \\n',tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262c194-88a9-481b-b410-de5d02cd0474",
   "metadata": {},
   "source": [
    "# For Larger Output optimize the code as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b969b17-5ed8-4d36-9c23-ad62e88a9dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrp;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    pre{\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"goolge/flan-t5-large\") # large x1\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"goolge/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069bb52c-649e-4d1b-95c4-b0f9fb141518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\", use_auth_token='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')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e40c04-4b64-41b3-8015-b873042b88f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ce696e-eb5e-4136-b76f-aac0a6be027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = 'Rewrite : Our usual sprint schedule is the first and third week of every month. However, we will not be able to accommodate your request on August 19th due to a scheduled network maintenance that day.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89cfd60-5680-4e40-a0f7-665b52e5fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Rewrite : Our usual sprint schedule is the first and third week of every month. However, we will not be able to accommodate your request on August 19th due to a scheduled network maintenance that day. If you have any questions, please don't hesitate to contact us. We will be happy to answer your questions and provide you with any additional information you may need. Thank you for your time and we look forward to working with you in the future.  Copyright 2019 - All Rights Reserved | Powered by WordPress | Theme: Spacious by ThemesGrill | Contact Us | Website: http://www.themesgrill.com/contact-us | Email: [email protected] | Phone: (212) 228-9998 | Fax: 212-256-9899 | E-mail: support@ThemesGirl.net | Support Center: https://support.templates.democracy.org/sponsors/support-center.php?utm_source=social-media-community | Twitter: Twitter.twitter@tweet.ru | Like us on Facebook | Tweet with us | Copy this link\", \"Rewrite : Our usual sprint schedule is the first and third week of every month. However, we will not be able to accommodate your request on August 19th due to a scheduled network maintenance that day. If you have any questions, please don't hesitate to contact us. We will be happy to answer your questions and provide you with any additional information you may need. Thank you for your time and we look forward to working with you in the future.  Copyright 2019 - All Rights Reserved | Powered by WordPress | Theme: Spacious by ThemesGrill | Contact Us | Website: http://www.themesgrill.com/contact-us | Email: [email protected] | Phone: (212) 228-9998 | Fax: 212-256-9899 | E-mail: support@ThemesGirl.net | Support Center: https://support.templates.democracy.org/sponsors/support-center.php?utm_source=social-media-community | Twitter: Twitter.twitter@tweet.ru | Like us on Facebook | Tweet with us | Copy this link:\"]\n",
      "CPU times: user 27min 36s, sys: 8min 9s, total: 35min 45s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inputs = tokenizer (my_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, \\\n",
    "                         min_length=256, \\\n",
    "                         max_new_tokens=512, \\\n",
    "                         length_penalty = 2, \\\n",
    "                         num_beams=16, \\\n",
    "                         no_repeat_ngram_size=2, \\\n",
    "                         num_return_sequences= 2, \\\n",
    "                         early_stopping=True)\n",
    "output_txt_flan_t5 = tokenizer.batch_decode(outputs,\\\n",
    "                                            skip_special_tokens=True)\n",
    "print(output_txt_flan_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93b0a4-4259-4651-aec4-3bbbbbec8912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
