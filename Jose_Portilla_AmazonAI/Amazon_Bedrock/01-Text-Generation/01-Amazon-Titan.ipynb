{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2855bf84-a3ff-4bdf-b36f-750a21cb5963",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afc7bb-89f2-45af-9ca8-0d5948e90ac0",
   "metadata": {},
   "source": [
    "# AWS Bedrock\n",
    "In this notebook we are going to inspect how to use AWS Bedrock, amazon's fully managed generative AI service to perform Text Generation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1ee10-5db5-482a-ae93-1779a52a0b16",
   "metadata": {},
   "source": [
    "## API connection\n",
    "\n",
    "Before starting, you need to initiate and configure **boto3**. \n",
    "\n",
    "We start by importing the boto3 library, which is the Amazon Web Services (AWS) SDK for Python. This SDK allows you to write software that makes use of AWS services\n",
    "\n",
    "Subsequently we create a client for the Bedrock service. This client is configured with the necessary credentials (AWS access key ID and AWS secret access key) and region (us-east-1) we want to operate in. Note that most bedrock services currently only work in the **us-east-1** region\n",
    "\n",
    "To verify that everything worked, we call *list_foundation_models()* to list all available models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef45c8e4-29cf-4430-b164-6d00f97f1e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd8a5207a-23bb-4638-97d6-cb5b2e0f7253',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 16 Dec 2023 09:16:11 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '17836',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'd8a5207a-23bb-4638-97d6-cb5b2e0f7253'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large',\n",
       "   'modelName': 'Titan Text Large',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0',\n",
       "   'modelId': 'amazon.titan-image-generator-v1:0',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1',\n",
       "   'modelId': 'amazon.titan-image-generator-v1',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02',\n",
       "   'modelName': 'Titan Text Embeddings v2',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelId': 'amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1',\n",
       "   'modelId': 'amazon.titan-text-lite-v1',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'modelId': 'amazon.titan-text-express-v1:0:8k',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelId': 'amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "   'modelId': 'amazon.titan-embed-image-v1:0',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1',\n",
       "   'modelId': 'amazon.titan-embed-image-v1',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1:0',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct',\n",
       "   'modelName': 'J2 Grande Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct',\n",
       "   'modelName': 'J2 Jumbo Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k',\n",
       "   'modelId': 'anthropic.claude-instant-v1:2:100k',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1:3:18k',\n",
       "   'modelId': 'anthropic.claude-v1:3:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1:3:100k',\n",
       "   'modelId': 'anthropic.claude-v1:3:100k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k',\n",
       "   'modelId': 'anthropic.claude-v2:0:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k',\n",
       "   'modelId': 'anthropic.claude-v2:0:100k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k',\n",
       "   'modelId': 'anthropic.claude-v2:1:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k',\n",
       "   'modelId': 'anthropic.claude-v2:1:200k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1',\n",
       "   'modelId': 'anthropic.claude-v2:1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-text-v14:7:4k',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-light-text-v14:7:4k',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14',\n",
       "   'modelId': 'cohere.command-light-text-v14',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3',\n",
       "   'modelId': 'cohere.embed-english-v3',\n",
       "   'modelName': 'Embed English',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3',\n",
       "   'modelId': 'cohere.embed-multilingual-v3',\n",
       "   'modelName': 'Embed Multilingual',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1',\n",
       "   'modelId': 'meta.llama2-13b-v1',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1',\n",
       "   'modelId': 'meta.llama2-70b-v1',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "bedrock = boto3.client(aws_access_key_id=\"\",\n",
    "                       aws_secret_access_key=\"\",\n",
    "                       region_name=\"us-east-1\", service_name='bedrock')\n",
    "bedrock.list_foundation_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec428a0a-1fe8-49ee-b687-6c778d7ee8ee",
   "metadata": {},
   "source": [
    "## Model Access\n",
    "As of today, you need to [request](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html) models prior to using them.\n",
    "To do so, navigate to https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess and request access to the models of your choice.\n",
    "\n",
    "[Here](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers) you can find an overview over the available models.\n",
    "\n",
    "In this notebook we will use the amazon.titan-text-express-v1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2192b4aa-ebd9-4ddf-b1ef-e7c7d0672ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'b7ec8de0-9a74-44d2-af77-f3c0a816bd8e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 16 Dec 2023 09:16:28 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '402',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'b7ec8de0-9a74-44d2-af77-f3c0a816bd8e'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelDetails': {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1',\n",
       "  'modelId': 'amazon.titan-text-express-v1',\n",
       "  'modelName': 'Titan Text G1 - Express',\n",
       "  'providerName': 'Amazon',\n",
       "  'inputModalities': ['TEXT'],\n",
       "  'outputModalities': ['TEXT'],\n",
       "  'responseStreamingSupported': True,\n",
       "  'customizationsSupported': [],\n",
       "  'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "  'modelLifecycle': {'status': 'ACTIVE'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.get_foundation_model(modelIdentifier='amazon.titan-text-express-v1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbb5a8-fe67-451b-8e50-8b8974ef132a",
   "metadata": {},
   "source": [
    "## Text Completion\n",
    "\n",
    "The first task is to perform text completion. Text completion is an AI-driven process where the system automatically completes sentences or paragraphs based on a given text prompt.\n",
    "\n",
    "### How Text Completion Works in AWS Bedrock\n",
    "\n",
    "1. **Provide a Prompt**: Start by providing an initial text prompt. This could be a sentence, a question, or even a few words. The prompt should be relevant to the context of the completion you need.\n",
    "\n",
    "2. **Configure the API**: Use the AWS Bedrock API to send the prompt. You may need to configure parameters such as the length of completion, the style of writing, or any specific instructions you want the AI to follow.\n",
    "\n",
    "3. **Receive the Completion**: The AWS Bedrock service processes the prompt and returns a text completion. This completion is generated in real-time and aims to be a natural extension of the input prompt.\n",
    "\n",
    "4. **Refinement and Iteration**: Depending on your needs, you might refine the initial prompt or adjust the parameters for different results. Iteration can help tailor the output to better suit your requirements.\n",
    "\n",
    "### Examples of Text Completion\n",
    "\n",
    "Here are a few examples of text completion tasks that can be accomplished with AWS Bedrock:\n",
    "\n",
    "- **Creative Writing**: Given the start of a story, AWS Bedrock can continue the narrative, maintaining the tone and style of the original text.\n",
    "\n",
    "- **Email Drafting**: For business communications, provide a brief outline or key points, and AWS Bedrock can formulate a complete, professional email.\n",
    "\n",
    "- **Code Suggestions**: When programming, input a part of the code, and the service can suggest logical code completions or bug fixes.\n",
    "\n",
    "- **Language Translation**: Begin with a sentence in one language, and AWS Bedrock can complete the translation, ensuring linguistic and contextual accuracy.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "To get the most out of text completion with AWS Bedrock:\n",
    "\n",
    "- **Provide Clear and Contextual Prompts**: The quality of the output is largely dependent on the input. Clear and contextual prompts yield better results.\n",
    "\n",
    "- **Iterative Approach**: Experiment with different prompts and settings. Iterative refinement can significantly enhance the outcome.\n",
    "\n",
    "- **Understand Limitations**: While powerful, generative AI models have limitations. Be aware of these and review outputs critically, especially for sensitive or critical applications.\n",
    "\n",
    "Let's get started by asking an absolute trivial question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e222dc-867f-41dd-bf49-b00ac82a9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the purpose of life?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c9464-277c-4854-982d-5973f2a3554e",
   "metadata": {},
   "source": [
    "## Titan API Call\n",
    "To invoke the model, we need to access the **bedrock-runtime** [service](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed05f58-d874-4757-9022-ed8bfa359853",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(aws_access_key_id=\"\",\n",
    "                               aws_secret_access_key=\"\",\n",
    "                               region_name=\"us-east-1\",\n",
    "                               service_name='bedrock-runtime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d236d9-9122-4ca6-a668-74e296816153",
   "metadata": {},
   "source": [
    "It provides the [invoke_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html) function to run inference.\n",
    "\n",
    "To use this function, we need to provide at least the following arguments:\n",
    "\n",
    "- body\n",
    "- modelId\n",
    "\n",
    "The request body looks diffrerent depending on the model you use. The parameters are listed [here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50c229-854e-4035-9180-cedcbfd2150c",
   "metadata": {},
   "source": [
    "### Titan Express Parameters\n",
    "AWS' titan text models accept the following parameters:\n",
    "\n",
    "- `inputText` [required]: string\n",
    "  - Input text (prompt)\n",
    "- `textGenerationConfig`[optional]:\n",
    "  - Configuration settings for text generation.\n",
    "  - `temperature`: float\n",
    "    - This controls the randomness in the text generation process. A higher temperature results in more random outputs, while a lower temperature produces more predictable text.\n",
    "  - `topP`: float\n",
    "    - This parameter, also known as \"nucleus sampling,\" controls the diversity of the generated text. It sets a threshold to include the most likely next words, cumulatively adding up to the specified probability 'P'. A lower value ignores less probable options.\n",
    "  - `maxTokenCount`: int\n",
    "    - This specifies the maximum number of tokens that the generated text can contain.\n",
    "  - `stopSequences`: [string]\n",
    "    - An array of string sequences that, when detected, will prompt the text generation to stop. This is useful for defining specific endpoints in generated text. \"Use the | (pipe) character to separate different sequences (maximum 20 characters).\"\n",
    "   \n",
    "Thus, the Titan model expects the following jsonified request body:\n",
    "```\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": float,  \n",
    "        \"topP\": float,\n",
    "        \"maxTokenCount\": int,\n",
    "        \"stopSequences\": [string]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Note you can always use the default values for the textGenerationConfig\n",
    "\n",
    "\n",
    "| Category              | Parameter        | JSON field format | Minimum | Maximum | Default |\n",
    "|-----------------------|------------------|-------------------|---------|---------|---------|\n",
    "| Randomness and diversity | Temperature     | `temperature`     | 0       | 1       | 0       |\n",
    "|                       | Top P            | `topP`            | 0       | 1       | 1       |\n",
    "| Length                | Response length  | `maxTokenCount`   | 0       | 8000    | 512     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0035a8-faf5-40ff-8c75-9cd38f129f8a",
   "metadata": {},
   "source": [
    "Alright! After all this information, let's send the first request to Titan using the default values! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110c05c0-364d-4a55-8884-02c3127e7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputText\": \"What is the purpose of life?\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "body = json.dumps({\n",
    "    \"inputText\": question,\n",
    "})\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a491c0c1-10fa-4bac-9c4e-517f34d1e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body, modelId=\"amazon.titan-text-express-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de4d035-08b5-4e36-8cfb-0970e91be787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '330a21a6-cdbc-4daa-9ce2-94f084883c88',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 16 Dec 2023 09:27:00 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '523',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '330a21a6-cdbc-4daa-9ce2-94f084883c88',\n",
       "   'x-amzn-bedrock-invocation-latency': '3141',\n",
       "   'x-amzn-bedrock-output-token-count': '79',\n",
       "   'x-amzn-bedrock-input-token-count': '7'},\n",
       "  'RetryAttempts': 0},\n",
       " 'contentType': 'application/json',\n",
       " 'body': <botocore.response.StreamingBody at 0x10f101c90>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef379666-eb39-40a5-83f4-f15d838185b4",
   "metadata": {},
   "source": [
    "### Model response\n",
    "The result is stored within the response body, that you can access as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e402220-1c19-40ef-b354-cf36d487223d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputTextTokenCount': 7,\n",
       " 'results': [{'tokenCount': 79,\n",
       "   'outputText': '\\nThe purpose of life varies from person to person. Some people find purpose in pursuing their passions, while others find purpose in helping others or making a positive impact on the world. Some people may find purpose in religious or spiritual beliefs, while others may find purpose in personal growth and self-discovery. Ultimately, the purpose of life is a personal journey that requires self-reflection and exploration.',\n",
       "   'completionReason': 'FINISH'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed5377-9933-4111-812d-6b359c00fdbd",
   "metadata": {},
   "source": [
    "**Important: Note that json.loads(response.get('body').read()) can only be executed once. After that the buffer is empty. So make sure to store the result!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adee15-7dac-4b05-84ac-04b5ff28645a",
   "metadata": {},
   "source": [
    "\n",
    "- `inputTextTokenCount`: int\n",
    "  -  Number of tokens in the input text.\n",
    "- `results`: array of objects\n",
    "    - `tokenCount`: int\n",
    "      - Number of tokens in the generated output. \n",
    "    - `outputText`: string\n",
    "      - This string contains the actual text that was generated or outputted. The text includes newline characters (`\\n`) to denote new lines or paragraphs in the generated text.\n",
    "    - `completionReason`: string\n",
    "      - Reason why the response terminated. Either:\n",
    "      - `FINISHED` – The response was fully generated.\n",
    "      - `LENGTH` – The response was truncated because of maxTokenCount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1842e39-b557-4c2f-9e63-7f06efa54fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The purpose of life varies from person to person. Some people find purpose in pursuing their passions, while others find purpose in helping others or making a positive impact on the world. Some people may find purpose in religious or spiritual beliefs, while others may find purpose in personal growth and self-discovery. Ultimately, the purpose of life is a personal journey that requires self-reflection and exploration.\n"
     ]
    }
   ],
   "source": [
    "print(response_body[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d512753-f501-45f6-9eff-001827b0812e",
   "metadata": {},
   "source": [
    "**What a beautiful answer!**\n",
    "However, a shorter answer would be nice, so let's reduce the max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5c7303-94d8-481b-ac01-9e9b1bd78630",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": question,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 20\n",
    "    }\n",
    "})\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=\"amazon.titan-text-express-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23045d1-09cb-4adf-8442-12ad1d782d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputTextTokenCount': 7,\n",
       " 'results': [{'tokenCount': 20,\n",
       "   'outputText': '\\nThe purpose of life varies from person to person. Some people find purpose in pursuing their passions,',\n",
       "   'completionReason': 'LENGTH'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f09e7-ce5c-480b-9a2d-6eba49418173",
   "metadata": {},
   "source": [
    "Note how the completionReason changed from FINISHED to LENGTH indicating that the answer was truncated because of maxTokenCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d942e-33e9-4f10-8e37-52456d3bea21",
   "metadata": {},
   "source": [
    "Let's try to get a better understanding of the parameters `temperature`and `topP` using the following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1862a796-98d7-4123-96b5-381d73af4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me a story\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103d272-156a-40e8-9862-57ff3ccce618",
   "metadata": {},
   "source": [
    "First, a basic approach with a very low temperature and topP to decrease randomness and ignore less probable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a97817c2-caca-46ed-829f-62de400d982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputTextTokenCount': 4,\n",
       " 'results': [{'tokenCount': 512,\n",
       "   'outputText': '\\n\"Once upon a time, there was a young man named John who lived in a small village on the outskirts of a great city. John was a simple man, with a heart full of kindness and a mind full of dreams. He had always wanted to travel the world, to see all the wonders that it had to offer, but he had never had the means to do so.\\n\\nOne day, while John was out for a walk in the countryside, he stumbled upon a hidden cave. Inside the cave, he found a beautiful crystal that glowed with an otherworldly light. John was amazed by the crystal\\'s beauty and he picked it up, feeling a strange energy coursing through his body.\\n\\nAs John left the cave and returned to his village, he felt a newfound sense of confidence and strength. He knew that the crystal had given him a special gift, and he was determined to use it to make his dreams a reality.\\n\\nOver the next few weeks, John worked tirelessly to save up enough money to travel the world. He sold his possessions, worked odd jobs, and even begged for change on the streets. Finally, he had enough money to buy a ticket to Europe.\\n\\nJohn arrived in Europe with a sense of excitement and wonder. He traveled from country to country, visiting ancient ruins, beautiful landscapes, and vibrant cities. He met new people, tried new foods, and experienced new cultures.\\n\\nAs John traveled, he began to notice that the crystal that he had found in the cave was giving him more and more power. He could feel a strange energy coursing through his body, and he knew that he was being guided by something greater than himself.\\n\\nOne day, while John was in a small village in France, he met a beautiful woman named Marie. Marie was a kind-hearted soul, and she immediately took a liking to John. They spent the day together, talking and laughing, and John felt a sense of joy and contentment that he had never felt before.\\n\\nAs the day drew to a close, John and Marie walked hand in hand back to John\\'s hotel. John knew that he had found something special in Marie, and he was determined to make her his wife.\\n\\nBut just as John was about to propose to Marie, he felt a strange sensation in his body. He looked down and saw that the crystal that he had found in the cave was glowing brightly, and he knew that it was calling him.\\n\\nJohn followed the crystal\\'s',\n",
       "   'completionReason': 'LENGTH'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": 0.01,  # needs to be larger than 0\n",
    "        \"maxTokenCount\": 512\n",
    "    }\n",
    "})\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=\"amazon.titan-text-express-v1\")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ab61fa4-3201-4bc7-b89a-493fc655ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Once upon a time, there was a young man named John who lived in a small village on the outskirts of a great city. John was a simple man, with a heart full of kindness and a mind full of dreams. He had always wanted to travel the world, to see all the wonders that it had to offer, but he had never had the means to do so.\n",
      "\n",
      "One day, while John was out for a walk in the countryside, he stumbled upon a hidden cave. Inside the cave, he found a beautiful crystal that glowed with an otherworldly light. John was amazed by the crystal's beauty and he picked it up, feeling a strange energy coursing through his body.\n",
      "\n",
      "As John left the cave and returned to his village, he felt a newfound sense of confidence and strength. He knew that the crystal had given him a special gift, and he was determined to use it to make his dreams a reality.\n",
      "\n",
      "Over the next few weeks, John worked tirelessly to save up enough money to travel the world. He sold his possessions, worked odd jobs, and even begged for change on the streets. Finally, he had enough money to buy a ticket to Europe.\n",
      "\n",
      "John arrived in Europe with a sense of excitement and wonder. He traveled from country to country, visiting ancient ruins, beautiful landscapes, and vibrant cities. He met new people, tried new foods, and experienced new cultures.\n",
      "\n",
      "As John traveled, he began to notice that the crystal that he had found in the cave was giving him more and more power. He could feel a strange energy coursing through his body, and he knew that he was being guided by something greater than himself.\n",
      "\n",
      "One day, while John was in a small village in France, he met a beautiful woman named Marie. Marie was a kind-hearted soul, and she immediately took a liking to John. They spent the day together, talking and laughing, and John felt a sense of joy and contentment that he had never felt before.\n",
      "\n",
      "As the day drew to a close, John and Marie walked hand in hand back to John's hotel. John knew that he had found something special in Marie, and he was determined to make her his wife.\n",
      "\n",
      "But just as John was about to propose to Marie, he felt a strange sensation in his body. He looked down and saw that the crystal that he had found in the cave was glowing brightly, and he knew that it was calling him.\n",
      "\n",
      "John followed the crystal's\n"
     ]
    }
   ],
   "source": [
    "print(response_body[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca700e5-06ff-4ea7-adf5-928cca1822ac",
   "metadata": {},
   "source": [
    "Let's compare that to a more creative model by  increasing temperature and topP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a870bae-e2f7-4cd4-811d-2647939db5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputTextTokenCount': 4,\n",
       " 'results': [{'tokenCount': 279,\n",
       "   'outputText': '\\n\\'When Johnny Comes Marching Home\\' is a popular marching tune written by John Philip Sousa in 1917. The song is not explicitly about the Vietnam War, but it has been commonly associated with it due to its patriotic and militaristic themes.\\n\\nThe song is set in the key of C major and has a tempo of 68 beats per minute. It features a marching rhythm with a trumpet solo and a catchy melody. The lyrics are as follows:\\n\\nWhen Johnny comes marching home again\\nHum drum drum, boys, hum drum drum\\nWhen Johnny comes marching home again\\nWe’ll give him a hoo-rah, hoo-rah, hoo-rah\\nWe’ll drive the girls wild, we’ll drive the boys wild\\nWhen Johnny comes marching home again\\n\\nThe song has been performed by numerous marching bands, including the United States Marine Band and the 76th Infantry Division Band. It has also been featured in a number of films, including the 1984 movie \"Platoon.\"\\n\\nDespite its association with the Vietnam War, \"When Johnny Comes Marching Home\" remains a popular and beloved patriotic song. It is a testament to the sacrifices made by soldiers and their families throughout history and serves as a reminder of the importance of supporting our military personnel and their families.',\n",
       "   'completionReason': 'FINISH'}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": 1,\n",
    "        \"topP\": 1,\n",
    "        \"maxTokenCount\": 512\n",
    "    }\n",
    "})\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=\"amazon.titan-text-express-v1\")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0778563-9201-4fb6-acc0-ec26152336ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'When Johnny Comes Marching Home' is a popular marching tune written by John Philip Sousa in 1917. The song is not explicitly about the Vietnam War, but it has been commonly associated with it due to its patriotic and militaristic themes.\n",
      "\n",
      "The song is set in the key of C major and has a tempo of 68 beats per minute. It features a marching rhythm with a trumpet solo and a catchy melody. The lyrics are as follows:\n",
      "\n",
      "When Johnny comes marching home again\n",
      "Hum drum drum, boys, hum drum drum\n",
      "When Johnny comes marching home again\n",
      "We’ll give him a hoo-rah, hoo-rah, hoo-rah\n",
      "We’ll drive the girls wild, we’ll drive the boys wild\n",
      "When Johnny comes marching home again\n",
      "\n",
      "The song has been performed by numerous marching bands, including the United States Marine Band and the 76th Infantry Division Band. It has also been featured in a number of films, including the 1984 movie \"Platoon.\"\n",
      "\n",
      "Despite its association with the Vietnam War, \"When Johnny Comes Marching Home\" remains a popular and beloved patriotic song. It is a testament to the sacrifices made by soldiers and their families throughout history and serves as a reminder of the importance of supporting our military personnel and their families.\n"
     ]
    }
   ],
   "source": [
    "print(response_body[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe09e6-6821-4320-ad9f-1813f15f990a",
   "metadata": {},
   "source": [
    "Well... You can see that by increasing temperature and topP your stories are getting more \"random\". \n",
    "Let's try something in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e3ba1fc-fb12-494d-b497-c76abddcdb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputTextTokenCount': 4,\n",
       " 'results': [{'tokenCount': 342,\n",
       "   'outputText': '\\n\"Once upon a time, there was a little girl named Lily. She loved to dance and spent most of her days twirling and leaping around the house. One day, her parents decided to enroll her in a dance class. Lily was thrilled and couldn\\'t wait to start.\\n\\nAt first, Lily was nervous. She didn\\'t know the other students and felt shy. But her teacher was patient and kind, and soon Lily began to feel more comfortable. She learned new dance moves and practiced every day.\\n\\nAs the weeks went by, Lily\\'s confidence grew. She started to perform in front of her classmates and even in small local competitions. She loved the feeling of being on stage, of feeling the music, and of sharing her passion with others.\\n\\nOne day, a famous dance company came to town to perform. Lily was thrilled when her teacher told her that she had been invited to perform with them. She practiced for weeks, perfecting her moves and building her confidence.\\n\\nThe day of the performance arrived, and Lily stepped onto the stage. She felt a rush of excitement and nerves as the music started. But as she danced, she forgot about her worries and felt like she was in a magical world. The audience was spellbound, and Lily received a standing ovation.\\n\\nFrom that day on, Lily knew that she wanted to be a professional dancer. She continued to study and practice, eventually joining a dance company and traveling the world performing. She knew that she had found her true calling, and she was grateful for every moment of it.\\n\\nAnd so, Lily lived happily ever after, dancing and spreading joy to everyone she met.\" ',\n",
       "   'completionReason': 'FINISH'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": 0.8,\n",
    "        \"topP\": 0.3,\n",
    "        \"maxTokenCount\": 512\n",
    "    }\n",
    "})\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=\"amazon.titan-text-express-v1\")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f789d569-e96c-44b6-8793-9ffe3e5b2c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Once upon a time, there was a little girl named Lily. She loved to dance and spent most of her days twirling and leaping around the house. One day, her parents decided to enroll her in a dance class. Lily was thrilled and couldn't wait to start.\n",
      "\n",
      "At first, Lily was nervous. She didn't know the other students and felt shy. But her teacher was patient and kind, and soon Lily began to feel more comfortable. She learned new dance moves and practiced every day.\n",
      "\n",
      "As the weeks went by, Lily's confidence grew. She started to perform in front of her classmates and even in small local competitions. She loved the feeling of being on stage, of feeling the music, and of sharing her passion with others.\n",
      "\n",
      "One day, a famous dance company came to town to perform. Lily was thrilled when her teacher told her that she had been invited to perform with them. She practiced for weeks, perfecting her moves and building her confidence.\n",
      "\n",
      "The day of the performance arrived, and Lily stepped onto the stage. She felt a rush of excitement and nerves as the music started. But as she danced, she forgot about her worries and felt like she was in a magical world. The audience was spellbound, and Lily received a standing ovation.\n",
      "\n",
      "From that day on, Lily knew that she wanted to be a professional dancer. She continued to study and practice, eventually joining a dance company and traveling the world performing. She knew that she had found her true calling, and she was grateful for every moment of it.\n",
      "\n",
      "And so, Lily lived happily ever after, dancing and spreading joy to everyone she met.\" \n"
     ]
    }
   ],
   "source": [
    "print(response_body[\"results\"][0][\"outputText\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
